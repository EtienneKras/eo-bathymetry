{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Etienne Kras, open in SDB_env\n",
    "\"\"\"\n",
    "\n",
    "# imports \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import gdal\n",
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import geojson\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from geojson import Feature, FeatureCollection, dump\n",
    "from shapely.geometry import Polygon\n",
    "from dateutil.relativedelta import *\n",
    "from google.cloud import storage\n",
    "from eepackages.applications import bathymetry\n",
    "from pathlib import Path\n",
    "from eepackages.utils import download_image_collection, download_image_collection_thumb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project specific toggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see scheme at acces_api.pdf for a workflow visualization \n",
    "\n",
    "# project toggles\n",
    "output_fol = r'p:\\satellite-derived-bathymetry' # name of the local folder to store files locally\n",
    "bucket = 'jip_calm_sdb' # name of the Google Cloud Storage bucket to store files in the cloud\n",
    "credential_file = r'p:\\11204209-jip-calm\\WT4.1_SDB\\GEE_images\\jip-calm-c1886b3313b9.json' # Cloud Storage credential key\n",
    "overall_project = 'RWS_SDB' # name of the overall project\n",
    "project_name = 'Friese_Zeegat' # name of the project AoI\n",
    "draw_AoI = 0 # toggle 1 to draw AoI, 0 to load\n",
    "\n",
    "# composite image toggles\n",
    "start_date = '2015-01-01' # start date of the composites\n",
    "stop_date = '2020-10-01' # end date of the composites\n",
    "compo_int = 3 # composite interval [months]\n",
    "compo_len = 24 # composite length [months]\n",
    "scale = 19.109  # output resolution of the image [m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing using the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and visualizing AoI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ce56be6fc7471b9fb231ea89d06f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[52.643246, 5.060993], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw or load Area of Interest (AoI)\n",
    "\n",
    "Map = geemap.Map(center=(52.643246, 5.060993), zoom=8) # initialize map with base in Hoorn\n",
    "\n",
    "if draw_AoI == 1:\n",
    "    print('Please draw a polygon somewhere in a water body') # identifier\n",
    "if draw_AoI == 0:\n",
    "    # open AoI\n",
    "    print('Loading and visualizing AoI') #identifier\n",
    "    AoIee = geemap.geojson_to_ee(os.path.join(os.getcwd(),'RWS_AOI',project_name+'.geojson'))\n",
    "    Map.addLayer(AoIee, {}, 'AoI')\n",
    "\n",
    "Map # show map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing AoI from loaded file\n"
     ]
    }
   ],
   "source": [
    "# (re)construct the AoI\n",
    "\n",
    "if draw_AoI == 1:\n",
    "    \n",
    "    print('Constructing AoI from drawn polygon') # identifier\n",
    "    \n",
    "    # get AoI \n",
    "    AoIee = ee.FeatureCollection(Map.draw_features) # make featurecollection\n",
    "    AoI = Polygon(AoIee.getInfo()['features'][0]['geometry']['coordinates'][0]) # create AoI shapefile\n",
    "\n",
    "    # export AoI\n",
    "    features = []\n",
    "    features.append(Feature(geometry=AoI, properties={\"AoI\": project_name}))\n",
    "    feature_collection = FeatureCollection(features)\n",
    "    with open(os.path.join(os.getcwd(),'RWS_AOI',project_name+'.geojson'), 'w') as f: # geojson\n",
    "        dump(feature_collection, f)\n",
    "    gdr = gpd.GeoDataFrame({'properties':{'AoI': project_name}, 'geometry': AoI}, crs='EPSG:4326') #shp\n",
    "    gdr.to_file(os.path.join(os.getcwd(),'RWS_AOI',project_name+'.shp'))\n",
    "    bounds = ee.Geometry.Polgyon([[[a,b] for a, b in zip(*AoI.exterior.coords.xy)]])\n",
    "    \n",
    "if draw_AoI == 0:\n",
    "    print('Reconstructing AoI from loaded file')\n",
    "    # get AoI\n",
    "    with open(os.path.join(os.getcwd(),'RWS_AOI',project_name+'.geojson')) as f:\n",
    "        AoIjson = geojson.load(f)\n",
    "    try: # drawn polygon in this script\n",
    "        AoI = Polygon(AoIjson['features'][0]['geometry']['coordinates'][0]) \n",
    "    except: # drawn in QGIS / ArcGIS and written to geojson there (client file)\n",
    "        AoI = Polygon(AoIjson['features'][0]['geometry']['coordinates'][0][0])\n",
    "    bounds = ee.Geometry.Polygon([[[a,b] for a, b in zip(*AoI.exterior.coords.xy)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create (subtidal) composites within AoI\n",
    "\n",
    "# image timeframes\n",
    "sdate = datetime.datetime.strptime(start_date,'%Y-%m-%d')\n",
    "edate = datetime.datetime.strptime(stop_date,'%Y-%m-%d')\n",
    "window_length = int((edate.year-sdate.year)*12+(edate.month-sdate.month))\n",
    "srangedates = pd.date_range(start_date, freq='%sMS'%(compo_int), periods=int((window_length-compo_len)/3)+1).strftime('%Y-%m-%d').tolist()\n",
    "erangedates = pd.date_range((sdate+relativedelta(months=compo_len)).strftime('%Y-%m-%d'), freq='%sMS'%(compo_int), periods=int((window_length-compo_len)/3)+1).strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "sdb = bathymetry.Bathymetry() # initialize sdb instance (class)\n",
    "\n",
    "# save composite ee.Images to a list (note, these are not yet processed)\n",
    "# for intertidal assessment see for example: \n",
    "# https://github.com/openearth/eo-bathymetry/blob/master/notebooks/rws-bathymetry/intertidal_bathymetry.ipynb\n",
    "image_list = []\n",
    "for starts, ends in zip(srangedates, erangedates):\n",
    "    \n",
    "    image = sdb.compute_inverse_depth(\n",
    "        bounds=bounds,\n",
    "        start=starts,\n",
    "        stop=ends,\n",
    "        scale=scale,\n",
    "        missions=['S2', 'L8'],\n",
    "        filter_masked=True,\n",
    "        skip_neighborhood_search=False,\n",
    "    ).clip(bounds) # clip to bounds \n",
    "    \n",
    "    image_list.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image (indicative)\n",
    "# note, this takes a while as image is processed in the cloud first\n",
    "\n",
    "AoIcenter = AoIee.geometry().centroid().coordinates()\n",
    "Map = geemap.Map(center=(AoIcenter.get(1).getInfo(), AoIcenter.get(0).getInfo()), zoom=12) \n",
    "Map.addLayer(AoIee, {}, 'AoI')\n",
    "Map.addLayer(image.select('red'), {}, 'composite')#, { \"min\": min, \"max\": max }, 'red-green-blue')\n",
    "Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset folder was already created, cannot overwrite\n",
      "tasks submitted, check progress at: https://code.earthengine.google.com/tasks\n"
     ]
    }
   ],
   "source": [
    "# store composites in assets or in cloud buckets (depending on your preference)\n",
    "store_asset = 1 # toggle 1 to save to asset imageCollection in Google Earth Engine (user account)\n",
    "store_gcs = 0 # toggle 1 to save to Google Cloud Storage (GCS) (user account), for service account GCS see for example: \n",
    "# https://github.com/openearth/eo-bathymetry/blob/master/notebooks/rws-bathymetry/test_service_user.ipynb\n",
    "\n",
    "# to assets --> visualize in Code Editor UI\n",
    "if store_asset == 1:\n",
    "    \n",
    "    # get user info from the server\n",
    "    user_name = ee.data.getAssetRoots()[0][\"id\"].split(\"/\")[-1]\n",
    "    asset_id = f'users/{user_name}/%s/%s'%(overall_project, project_name)\n",
    "\n",
    "    # create folder\n",
    "    try:\n",
    "        ee.data.createAsset({'type': 'Folder'}, '/'.join(asset_id.split('/')[:-1]))\n",
    "    except:\n",
    "        print('Asset folder was already created, cannot overwrite')\n",
    "    \n",
    "    # create empty imageCollection\n",
    "    try: \n",
    "        ee.data.createAsset({'type': 'ImageCollection'}, asset_id)\n",
    "    except:\n",
    "        print('Asset imageCollection was already created, cannot overwrite')\n",
    "    \n",
    "    # start ingesting images into imageCollection\n",
    "    for img, start, end in zip(image_list, srangedates, erangedates):\n",
    "        task = ee.batch.Export.image.toAsset(**{\n",
    "            'image': img,\n",
    "            'description': '%s_%s_%s'%(project_name, start, end),\n",
    "            'scale': scale,\n",
    "            'region': bounds,\n",
    "            'assetId': asset_id + '/%s_%s_%s'%(project_name, start, end),\n",
    "            'maxPixels': 1e11,\n",
    "            'crs': 'EPSG:3857'\n",
    "        })\n",
    "        task.start()\n",
    "        \n",
    "    print('tasks submitted, check progress at: https://code.earthengine.google.com/tasks')\n",
    "\n",
    "# to cloud storage \n",
    "if store_gcs == 1:\n",
    "    for img, start, end in zip(image_list, srangedates, erangedates):\n",
    "        task = ee.batch.Export.image.toCloudStorage(**{\n",
    "            'image': img, \n",
    "            'description': '%s_%s_%s'%(project_name, start, end),\n",
    "            'scale': scale,\n",
    "            'region': bounds,\n",
    "            'fileNamePrefix': '%s/%s/%s_%s_%s'%(overall_project, project_name, project_name, start, end),\n",
    "            'fileFormat': 'GeoTIFF',\n",
    "            'bucket': bucket, \n",
    "            'formatOptions': {'cloudOptimized': True}, # enables easy QGIS plotting\n",
    "            'maxPixels': 1e11,\n",
    "            'crs': 'EPSG:3857',\n",
    "        })\n",
    "        task.start()\n",
    "        \n",
    "    print('tasks submitted, check progress at: https://code.earthengine.google.com/tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored:  Friese_Zeegat_2015-01-01_2017-01-01.tif\n",
      "Stored:  Friese_Zeegat_2015-04-01_2017-04-01.tif\n",
      "Stored:  Friese_Zeegat_2015-07-01_2017-07-01.tif\n",
      "Stored:  Friese_Zeegat_2015-10-01_2017-10-01.tif\n",
      "Stored:  Friese_Zeegat_2016-01-01_2018-01-01.tif\n",
      "Stored:  Friese_Zeegat_2016-04-01_2018-04-01.tif\n",
      "Stored:  Friese_Zeegat_2016-07-01_2018-07-01.tif\n",
      "Stored:  Friese_Zeegat_2016-10-01_2018-10-01.tif\n",
      "Stored:  Friese_Zeegat_2017-01-01_2019-01-01.tif\n",
      "Stored:  Friese_Zeegat_2017-04-01_2019-04-01.tif\n",
      "Stored:  Friese_Zeegat_2017-07-01_2019-07-01.tif\n",
      "Stored:  Friese_Zeegat_2017-10-01_2019-10-01.tif\n",
      "Stored:  Friese_Zeegat_2018-01-01_2020-01-01.tif\n",
      "Stored:  Friese_Zeegat_2018-04-01_2020-04-01.tif\n",
      "Stored:  Friese_Zeegat_2018-07-01_2020-07-01.tif\n",
      "Stored:  Friese_Zeegat_2018-10-01_2020-10-01.tif\n"
     ]
    }
   ],
   "source": [
    "# store composite locally (from GCS)\n",
    "local_store = 1 # toggle 1 to save to local drive\n",
    "\n",
    "# to a local folder --> visualize in QGIS / ArcGIS (download via Cloud Storage platform or enable local storage toggle)\n",
    "if local_store == 1:\n",
    "\n",
    "    # create or check if local storage folder is present\n",
    "    if not os.path.exists(os.path.join(output_fol, overall_project, project_name)):\n",
    "        os.makedirs(os.path.join(output_fol, overall_project, project_name))\n",
    "    \n",
    "    # authentication\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_file\n",
    "    \n",
    "    # get file names\n",
    "    client = storage.Client()\n",
    "    ls = [blob for blob in client.list_blobs(bucket)] \n",
    "    \n",
    "    # downloading composites to a local folder\n",
    "    check_files = []\n",
    "    for blob in ls:\n",
    "        if project_name in blob.name:\n",
    "            check_files.append(blob.name.split('/')[-1])\n",
    "            blob.download_to_filename(os.path.join(output_fol, overall_project, project_name, blob.name.split('/')[-1]))\n",
    "            print('Stored: ', blob.name.split('/')[-1]) # check progress\n",
    "    \n",
    "    # elaborate on possibility of storing locally\n",
    "    if len(check_files) == 0:\n",
    "        print('Please enable GCS storeing of images first, before toggling on local storage option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable single image downloading in the created composites.. (see for example: https://github.com/openearth/eo-bathymetry/blob/master/notebooks/rws-bathymetry/Download_SDB_ImageCollection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\__init__.py\", line 44, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 41, in <module>\n",
      "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\__init__.py\", line 44, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"C:\\Users\\kras\\Anaconda3\\envs\\SDB_env\\lib\\site-packages\\googleapiclient\\discovery_cache\\file_cache.py\", line 41, in <module>\n",
      "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
     ]
    }
   ],
   "source": [
    "#import logging\n",
    "#logging.basicConfig()\n",
    "#\n",
    "#sdb = bathymetry.Bathymetry() # initialize sdb instance (class)\n",
    "#    \n",
    "#image = sdb.compute_inverse_depth(\n",
    "#    bounds=bounds,\n",
    "#    start=srangedates[0],\n",
    "#    stop=erangedates[0],\n",
    "#    scale=scale,\n",
    "#    missions=['S2', 'L8'],\n",
    "#    filter_masked=True,\n",
    "#    skip_neighborhood_search=False,\n",
    "#).clip(bounds) # clip to bounds \n",
    "#\n",
    "## create or check if local storage folder is present\n",
    "#if not os.path.exists(os.path.join(output_fol, overall_project, project_name, 'single_images')):\n",
    "#    os.makedirs(os.path.join(output_fol, overall_project, project_name, 'single_images'))\n",
    "#    \n",
    "## download and store remaining cloud-free images in the composite imageCollection\n",
    "#imgCol = sdb._raw_images.map(lambda img: img.clip(bounds))\n",
    "#download_image_collection(imgCol, out_dir=Path(os.path.join(output_fol, overall_project, project_name, 'single_images')), download_kwargs={\"format\": \"GEO_TIFF\", \"scale\": scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
